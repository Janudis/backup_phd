{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.path.append(\"../\")\n",
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "from visualDet3D.data.kitti.utils import write_result_to_file\n",
    "from visualDet3D.utils.utils import LossLogger, cfg_from_file\n",
    "from visualDet3D.networks.utils.registry import DETECTOR_DICT, DATASET_DICT, PIPELINE_DICT\n",
    "from visualDet3D.networks.heads.anchors import Anchors\n",
    "from visualDet3D.networks.lib.fast_utils.hill_climbing import post_opt\n",
    "from visualDet3D.networks.utils import BBox3dProjector, BackProjection\n",
    "from visualDet3D.utils.utils import convertAlpha2Rot, convertRot2Alpha, draw_3D_box, compound_annotation\n",
    "import visualDet3D.data.kitti.dataset\n",
    "from visualDet3D.utils.timer import Timer\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "cfg = cfg_from_file('D:/Python_Projects/self_driving_car/nuscenes-devkit/python-sdk/nuscenes/visualDet3D/config/config.py')\n",
    "is_test_train = True\n",
    "\n",
    "checkpoint_name = 'D:/Python_Projects/self_driving_car/nuscenes-devkit/python-sdk/nuscenes/visualDet3D/workdirs/Mono3D/checkpoint/GroundAware_pretrained.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox2d_to_image(image, bboxes2d, color=(255, 0, 255)):\n",
    "    drawed_image = image.copy()\n",
    "    for box2d in bboxes2d:\n",
    "        cv2.rectangle(drawed_image, (int(box2d[0]), int(box2d[1])), (int(box2d[2]), int(box2d[3])), color, 3)\n",
    "    return drawed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualDet3D.networks.detectors.yolomono3d_detector import GroundAwareYolo3D\n",
    "\n",
    "#detector = DETECTOR_DICT[cfg.detector.name](cfg.detector)\n",
    "detector = DETECTOR_DICT[cfg.detector.name](cfg.detector)\n",
    "detector = detector.cuda()\n",
    "\n",
    "weight_path = os.path.join(cfg.path.checkpoint_path, checkpoint_name)\n",
    "state_dict = torch.load(weight_path, map_location='cuda:{}'.format(cfg.trainer.gpu))\n",
    "new_dict = state_dict.copy()\n",
    "for key in state_dict:\n",
    "    if 'focalLoss' in key:\n",
    "        new_dict.pop(key)\n",
    "detector.load_state_dict(new_dict, strict=False)\n",
    "detector.eval().cuda()\n",
    "\n",
    "# testing pipeline\n",
    "test_func = PIPELINE_DICT[cfg.trainer.test_func]\n",
    "\n",
    "projector = BBox3dProjector().cuda()\n",
    "backprojector = BackProjection().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "def corner_homo2bbox(corner_homo):\n",
    "    \"\"\"\n",
    "        corner_homo: [N, 8, 3]\n",
    "    \"\"\"\n",
    "    min_xy  = torch.min(corner_homo[:, :, 0:2], dim=1)[0]\n",
    "    max_xy  = torch.max(corner_homo[:, :, 0:2], dim=1)[0]\n",
    "    min_xy[:, 0]  = torch.clamp(min_xy[:, 0], 0, cfg.rgb_shape[1])\n",
    "    min_xy[:, 1]  = torch.clamp(min_xy[:, 1], 0, cfg.rgb_shape[0])\n",
    "    max_xy[:, 0]  = torch.clamp(max_xy[:, 0], 0, cfg.rgb_shape[1])\n",
    "    max_xy[:, 1]  = torch.clamp(max_xy[:, 1], 0, cfg.rgb_shape[0])\n",
    "    return torch.cat([min_xy, max_xy], dim=1)\n",
    "\n",
    "def denorm(image):\n",
    "    new_image = np.array((image * cfg.data.augmentation.rgb_std +  cfg.data.augmentation.rgb_mean) * 255, dtype=np.uint8)\n",
    "    return new_image\n",
    "\n",
    "@jit(cache=True, nopython=True)\n",
    "def ToColorDepth(depth_image:np.ndarray)->np.ndarray: #[H, W] -> [H, W, 3] # Used to draw depth predictions\n",
    "    H, W = depth_image.shape\n",
    "    max_depth = float(np.max(depth_image))\n",
    "    cmap = np.array([\n",
    "        [0,0,0,114],[0,0,1,185],[1,0,0,114],[1,0,1,174], \n",
    "        [0,1,0,114],[0,1,1,185],[1,1,0,114],[1,1,1,0]\n",
    "    ])\n",
    "    _sum  = 0\n",
    "    for i in range(8):\n",
    "        _sum += cmap[i, 3]\n",
    "    \n",
    "    weights = np.zeros(8)\n",
    "    cumsum = np.zeros(8)\n",
    "    for i in range(7):\n",
    "        weights[i] = _sum / cmap[i, 3]\n",
    "        cumsum[i+1] = cumsum[i] + cmap[i, 3] / _sum\n",
    "    \n",
    "    image = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            val = depth_image[i, j] / max_depth\n",
    "            for k in range(7):\n",
    "                if val <= cumsum[k + 1]:\n",
    "                    break\n",
    "            w = 1.0- (val - cumsum[k]) * weights[k]\n",
    "            r = int( (w * cmap[k, 0] + (1 - w) * cmap[k+1, 0]) * 255 )\n",
    "            g = int( (w * cmap[k, 1] + (1 - w) * cmap[k+1, 1]) * 255 )\n",
    "            b = int( (w * cmap[k, 2] + (1 - w) * cmap[k+1, 2]) * 255 )\n",
    "            image[i, j] = np.array([r,g,b])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualDet3D.data.pipeline import build_augmentator\n",
    "def compute_once(index, is_draw=True, is_test_train=True):\n",
    "    transform = build_augmentator(cfg.data.test_augmentation)\n",
    "    name = \"%06d\" % index\n",
    "\n",
    "    data = dataset[index]\n",
    "    if isinstance(data['calib'], list):\n",
    "        P2 = data['calib'][0]\n",
    "    else:\n",
    "        P2 = data['calib']\n",
    "    \n",
    "    original_height = data['original_shape'][0]\n",
    "    collated_data = dataset.collate_fn([data])\n",
    "    height = collated_data[0].shape[2]\n",
    "    scale_2d = (original_height - cfg.data.augmentation.crop_top) / height\n",
    "    \n",
    "    if len(collated_data) > 6:\n",
    "        left_images, P2, _, _, labels, bbox_3d, _ = collated_data\n",
    "    else:\n",
    "        left_images, P2, labels, _, bbox_3d = collated_data\n",
    "    \n",
    "    image = left_images\n",
    "    # imagenp = image.numpy()  \n",
    "    # new_imagenp, new_p2 = transform(imagenp.copy(), p2=P2.copy())\n",
    "    test_func = PIPELINE_DICT[cfg.trainer.test_func]\n",
    "    with torch.no_grad():\n",
    "        #print(collated_data[3])\n",
    "        #left_images, right_images, P2, P3 = collated_data[0], collated_data[1], collated_data[2], collated_data[3]\n",
    "        scores, bbox, obj_names = test_func(collated_data, detector, None, cfg=cfg)\n",
    "        # scores, bbox, obj_names = detector([left_images.cuda().float().contiguous(),\n",
    "        #                                   right_images.cuda().float().contiguous(),\n",
    "        #                                   P2,\n",
    "        #                                   P3])\n",
    "        #print(P2)\n",
    "        P2 = P2[0]\n",
    "        bbox_2d = bbox[:, 0:4]\n",
    "        bbox_3d_state = bbox[:, 4:] #[cx,cy,z,w,h,l,alpha]\n",
    "        bbox_3d_state_3d = backprojector(bbox_3d_state, P2.cuda()) #[x, y, z, w,h ,l, alpha]\n",
    "        abs_bbox, bbox_3d_corner_homo, thetas = projector(bbox_3d_state_3d, P2.cuda())\n",
    "\n",
    "        \n",
    "    \n",
    "    rgb_image = denorm(image[0].cpu().numpy().transpose([1, 2, 0]))\n",
    "    if len(scores) > 0:\n",
    "        rgb_image = draw_bbox2d_to_image(rgb_image, bbox_2d.cpu().numpy())\n",
    "        for box in bbox_3d_corner_homo:\n",
    "            box = box.cpu().numpy().T\n",
    "            rgb_image = draw_3D_box(rgb_image, box)\n",
    "    if is_draw:\n",
    "        plt.imshow(np.clip(rgb_image, 0, 255))\n",
    "\n",
    "    return np.clip(rgb_image, 0, 255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
